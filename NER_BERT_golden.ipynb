{"cells":[{"cell_type":"code","execution_count":39,"id":"p7QH2OAexwh5","metadata":{"id":"p7QH2OAexwh5","executionInfo":{"status":"ok","timestamp":1756251465898,"user_tz":-480,"elapsed":4,"user":{"displayName":"宋若冰","userId":"16843204755956256636"}}},"outputs":[],"source":["# !pip install seqeval"]},{"cell_type":"code","execution_count":40,"id":"e-yOTRURAZ72","metadata":{"id":"e-yOTRURAZ72","executionInfo":{"status":"ok","timestamp":1756251465899,"user_tz":-480,"elapsed":2,"user":{"displayName":"宋若冰","userId":"16843204755956256636"}}},"outputs":[],"source":["# !pip install evaluate"]},{"cell_type":"code","execution_count":41,"id":"55ViNYK1GMg-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":950,"status":"ok","timestamp":1756251466849,"user":{"displayName":"宋若冰","userId":"16843204755956256636"},"user_tz":-480},"id":"55ViNYK1GMg-","outputId":"e15f76d6-bcbe-4ccf-82a0-c4c52c91df46"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","base_path = '/content/drive/MyDrive/NLP/'"]},{"cell_type":"code","execution_count":42,"id":"k1xIn_5iHfTm","metadata":{"id":"k1xIn_5iHfTm","executionInfo":{"status":"ok","timestamp":1756251466852,"user_tz":-480,"elapsed":2,"user":{"displayName":"宋若冰","userId":"16843204755956256636"}}},"outputs":[],"source":["import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\""]},{"cell_type":"code","execution_count":43,"id":"fc9e92bf-1159-40e4-b3c4-17a94345cafc","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1756251467094,"user":{"displayName":"宋若冰","userId":"16843204755956256636"},"user_tz":-480},"id":"fc9e92bf-1159-40e4-b3c4-17a94345cafc","outputId":"55ecc003-a16c-44f8-bb9c-bc151a0d954f"},"outputs":[{"output_type":"stream","name":"stdout","text":["7 types of entities are discovered:\n","- AGE_ONSET: 93 samples\n","- PATIENT: 246 samples\n","- HPO_TERM: 2525 samples\n","- GENE: 252 samples\n","- GENE_VARIANT: 404 samples\n","- AGE_FOLLOWUP: 76 samples\n","- AGE_DEATH: 29 samples\n"]}],"source":["import json\n","from collections import defaultdict\n","import numpy as np\n","from transformers import AutoTokenizer, AutoModelForTokenClassification\n","from transformers import TrainingArguments, Trainer\n","from transformers import EarlyStoppingCallback\n","from sklearn.metrics import classification_report as sk_classification_report\n","from sklearn.metrics import accuracy_score\n","from datasets import Dataset\n","import torch\n","import random\n","from collections import Counter\n","from transformers import set_seed\n","\n","SEED = 42\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(SEED)\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","\n","set_seed(SEED)\n","\n","def convert_to_iob(entries):\n","    samples = []\n","    label_map = defaultdict(list)\n","\n","    for entry in entries:\n","        tokens = entry[\"tokens\"]\n","        text = entry[\"text\"]\n","        spans = entry.get(\"spans\", [])\n","\n","        labels = [\"O\"] * len(tokens)\n","\n","        for span in spans:\n","            start_token = span[\"token_start\"]\n","            end_token = span[\"token_end\"]\n","            label = span[\"label\"]\n","\n","            labels[start_token] = f\"B-{label}\"\n","            for i in range(start_token + 1, end_token + 1):\n","                labels[i] = f\"I-{label}\"\n","\n","            label_map[label].append(span)\n","\n","        token_label_pairs = [\n","            (token[\"text\"], label)\n","            for token, label in zip(tokens, labels)\n","        ]\n","        samples.append(token_label_pairs)\n","\n","    return samples, label_map\n","\n","entries_silver = []\n","entries_golden = []\n","with open(base_path+\"dataset/synthesis/silver.jsonl\", \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        entries_silver.append(json.loads(line))\n","\n","with open(base_path+\"dataset/cleaned/NER/processed_merged.jsonl\", \"r\", encoding=\"utf-8\") as f:\n","    for line in f:\n","        entries_golden.append(json.loads(line))\n","\n","silver_data, label_stats_silver = convert_to_iob(entries_silver)\n","golden_data, label_stats_golden = convert_to_iob(entries_golden)\n","\n","# Printed label statistics\n","print(f\"{len(label_stats_golden)} types of entities are discovered:\")\n","for label, spans in label_stats_golden.items():\n","    print(f\"- {label}: {len(spans)} samples\")"]},{"cell_type":"code","execution_count":44,"id":"fe58704b-22e6-4be8-a758-ac7a6b93ffee","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3930,"status":"ok","timestamp":1756251471026,"user":{"displayName":"宋若冰","userId":"16843204755956256636"},"user_tz":-480},"id":"fe58704b-22e6-4be8-a758-ac7a6b93ffee","outputId":"f3244164-d2b4-4d15-e31b-6342a9ec49f2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["label_list = [\"O\"] + [\n","    f\"{pre}-{label}\"\n","    for label in label_stats_golden.keys()\n","    for pre in [\"B\", \"I\"]\n","]\n","\n","# model_name = \"bert-base-cased\"\n","# model_name = \"allenai/scibert_scivocab_uncased\"\n","# model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n","model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\"\n","# model_name = \"prajjwal1/bert-tiny\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForTokenClassification.from_pretrained(\n","    model_name,\n","    num_labels=len(label_list),\n","    id2label={i: label for i, label in enumerate(label_list)},\n","    label2id={label: i for i, label in enumerate(label_list)}\n",")\n"]},{"cell_type":"code","execution_count":45,"id":"771a7c09-7e27-40c9-85d9-76ca87aab225","metadata":{"id":"771a7c09-7e27-40c9-85d9-76ca87aab225","executionInfo":{"status":"ok","timestamp":1756251471751,"user_tz":-480,"elapsed":712,"user":{"displayName":"宋若冰","userId":"16843204755956256636"}}},"outputs":[],"source":["def encode_data(examples):\n","    tokenized_inputs = tokenizer(\n","        examples[\"tokens\"],\n","        truncation=True,\n","        is_split_into_words=True,\n","        padding=\"max_length\",\n","        max_length=256\n","    )\n","\n","    label = examples[\"labels\"]\n","    word_ids = tokenized_inputs.word_ids()\n","    previous_word_idx = None\n","    label_ids = []\n","\n","    for word_idx in word_ids:\n","        if word_idx is None:\n","            label_ids.append(-100)\n","        elif word_idx != previous_word_idx:\n","            label_ids.append(label[word_idx])\n","        else:\n","            label_ids.append(-100)\n","        previous_word_idx = word_idx\n","\n","    tokenized_inputs[\"labels\"] = label_ids\n","    return tokenized_inputs\n","\n","formatted_data_silver = [{\"tokens\": [t[0] for t in sample], \"labels\": [label_list.index(t[1]) for t in sample]}\n","                 for sample in silver_data]\n","formatted_data_golden = [{\"tokens\": [t[0] for t in sample], \"labels\": [label_list.index(t[1]) for t in sample]}\n","                 for sample in golden_data]\n","\n","from sklearn.model_selection import train_test_split\n","train_set, temp_set = train_test_split(formatted_data_golden, test_size=0.3, random_state=SEED)\n","val_set, test_set = train_test_split(temp_set, test_size=0.5, random_state=SEED)\n","\n","encoded_train = [encode_data(d) for d in train_set]\n","encoded_val = [encode_data(d) for d in val_set]\n","encoded_test = [encode_data(d) for d in test_set]"]},{"cell_type":"code","execution_count":46,"id":"3a7c2876-30cc-496a-839e-c0ca003da03f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":525},"executionInfo":{"elapsed":364431,"status":"ok","timestamp":1756251836178,"user":{"displayName":"宋若冰","userId":"16843204755956256636"},"user_tz":-480},"id":"3a7c2876-30cc-496a-839e-c0ca003da03f","outputId":"5ed51764-ecf4-4bdf-dc0d-b15c3f03a065"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1632934140.py:79: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='513' max='855' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [513/855 06:02 < 04:02, 1.41 it/s, Epoch 9/15]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Strict Precision</th>\n","      <th>Strict Recall</th>\n","      <th>Strict F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.043100</td>\n","      <td>0.279032</td>\n","      <td>0.642942</td>\n","      <td>0.650748</td>\n","      <td>0.645569</td>\n","      <td>0.419732</td>\n","      <td>0.454710</td>\n","      <td>0.436522</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.229200</td>\n","      <td>0.230018</td>\n","      <td>0.666953</td>\n","      <td>0.846044</td>\n","      <td>0.739315</td>\n","      <td>0.498695</td>\n","      <td>0.692029</td>\n","      <td>0.579666</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.153900</td>\n","      <td>0.190838</td>\n","      <td>0.811361</td>\n","      <td>0.739130</td>\n","      <td>0.769667</td>\n","      <td>0.579119</td>\n","      <td>0.643116</td>\n","      <td>0.609442</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.100700</td>\n","      <td>0.205735</td>\n","      <td>0.766812</td>\n","      <td>0.796151</td>\n","      <td>0.779728</td>\n","      <td>0.601246</td>\n","      <td>0.699275</td>\n","      <td>0.646566</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.071100</td>\n","      <td>0.240439</td>\n","      <td>0.768283</td>\n","      <td>0.802566</td>\n","      <td>0.783661</td>\n","      <td>0.601246</td>\n","      <td>0.699275</td>\n","      <td>0.646566</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.052100</td>\n","      <td>0.232355</td>\n","      <td>0.797705</td>\n","      <td>0.791162</td>\n","      <td>0.791657</td>\n","      <td>0.639033</td>\n","      <td>0.670290</td>\n","      <td>0.654288</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.036900</td>\n","      <td>0.292072</td>\n","      <td>0.806452</td>\n","      <td>0.779758</td>\n","      <td>0.791380</td>\n","      <td>0.649396</td>\n","      <td>0.681159</td>\n","      <td>0.664898</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.029300</td>\n","      <td>0.296120</td>\n","      <td>0.763525</td>\n","      <td>0.818247</td>\n","      <td>0.788764</td>\n","      <td>0.612245</td>\n","      <td>0.706522</td>\n","      <td>0.656013</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.018800</td>\n","      <td>0.349296</td>\n","      <td>0.839112</td>\n","      <td>0.729152</td>\n","      <td>0.778469</td>\n","      <td>0.648598</td>\n","      <td>0.628623</td>\n","      <td>0.638454</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.12/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=513, training_loss=0.19278987597303782, metrics={'train_runtime': 362.6578, 'train_samples_per_second': 18.613, 'train_steps_per_second': 2.358, 'total_flos': 529188121728000.0, 'train_loss': 0.19278987597303782, 'epoch': 9.0})"]},"metadata":{},"execution_count":46}],"source":["training_args = TrainingArguments(\n","    output_dir=base_path + \"./model/NER\",\n","    eval_strategy=\"epoch\",\n","    num_train_epochs=15,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    learning_rate=5e-5,\n","    weight_decay=0.05,\n","    warmup_ratio=0.05,\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n","    seed=SEED,\n","    metric_for_best_model=\"strict_f1\",\n","    save_total_limit=2,\n","    logging_strategy=\"epoch\",\n","    report_to=\"none\",\n",")\n","\n","from evaluate import load\n","seqeval = load(\"seqeval\")\n","\n","from itertools import chain\n","\n","def is_loose_match(true_tag, pred_tag):\n","    if true_tag != \"O\" and pred_tag != \"O\":\n","        return true_tag.split(\"-\")[-1] == pred_tag.split(\"-\")[-1]\n","    return False\n","\n","def strip_prefix(tag):\n","    return tag.split(\"-\")[-1] if tag != \"O\" else \"O\"\n","\n","def compute_metrics(p):\n","    predictions, labels = p\n","    pred_ids = np.argmax(predictions, axis=2)\n","\n","    true_labels = [[label_list[l] for l in lab if l != -100] for lab in labels]\n","    pred_labels = [[label_list[p] for p, l in zip(pred, lab) if l != -100]\n","            for pred, lab in zip(pred_ids, labels)]\n","\n","    # Strict matching\n","    strict = seqeval.compute(predictions=pred_labels, references=true_labels)\n","    strict_precision = strict[\"overall_precision\"]\n","    strict_recall = strict[\"overall_recall\"]\n","    strict_f1 = strict[\"overall_f1\"]\n","\n","    # Loose matching\n","    flat_true = list(chain.from_iterable(true_labels))\n","    flat_pred = list(chain.from_iterable(pred_labels))\n","\n","    adjusted_pred = [t if is_loose_match(t, p) else p for t, p in zip(flat_true, flat_pred)]\n","\n","    flat_true_no_prefix = [strip_prefix(t) for t in flat_true]\n","    adjusted_pred_no_prefix = [strip_prefix(p) for p in adjusted_pred]\n","\n","    labels_without_O = sorted((set(flat_true_no_prefix) | set(adjusted_pred_no_prefix)) - {\"O\"})\n","\n","    report = sk_classification_report(\n","        flat_true_no_prefix,\n","        adjusted_pred_no_prefix,\n","        labels=labels_without_O,\n","        output_dict=True,\n","        zero_division=0\n","    )\n","\n","    loose_precision = report[\"weighted avg\"][\"precision\"]\n","    loose_recall = report[\"weighted avg\"][\"recall\"]\n","    loose_f1 = report[\"weighted avg\"][\"f1-score\"]\n","\n","    return {\n","        \"precision\": loose_precision,\n","        \"recall\": loose_recall,\n","        \"f1\": loose_f1,\n","\n","        \"strict_precision\": strict_precision,\n","        \"strict_recall\": strict_recall,\n","        \"strict_f1\": strict_f1\n","    }\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=encoded_train,\n","    eval_dataset=encoded_val,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",")\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":47,"id":"S35NVofIzWVg","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"elapsed":1764,"status":"ok","timestamp":1756251837929,"user":{"displayName":"宋若冰","userId":"16843204755956256636"},"user_tz":-480},"id":"S35NVofIzWVg","outputId":"8e3714ec-e1d4-4f24-ade5-8cd6f51b7f36"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}],"source":["dataset_test = encoded_test\n","results = trainer.predict(dataset_test)\n","\n","logits = results.predictions\n","label_ids = results.label_ids\n","\n","pred_indices = np.argmax(logits, axis=-1)\n","\n","true_labels = []\n","pred_labels = []\n","\n","for i in range(len(label_ids)):\n","    true_seq = label_ids[i]\n","    pred_seq = pred_indices[i]\n","\n","    filtered_true = [label_list[l] for l in true_seq if l != -100]\n","    filtered_pred = [label_list[p] for p, l in zip(pred_seq, true_seq) if l != -100]\n","\n","    true_labels.append(filtered_true)\n","    pred_labels.append(filtered_pred)"]},{"cell_type":"code","execution_count":48,"id":"ErQ8eqVbvRDw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1756251838241,"user":{"displayName":"宋若冰","userId":"16843204755956256636"},"user_tz":-480},"id":"ErQ8eqVbvRDw","outputId":"2990be7d-9500-46f0-9dd5-d3f800805e98"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9365\n","Precision: 0.6660\n","Recall: 0.6934\n","F1-Score: 0.6783\n","              precision    recall  f1-score   support\n","\n","   AGE_DEATH       0.00      0.00      0.00         3\n","AGE_FOLLOWUP       0.56      0.45      0.50        11\n","   AGE_ONSET       0.17      0.36      0.24        11\n","        GENE       0.89      0.85      0.87        40\n","GENE_VARIANT       0.83      0.83      0.83        78\n","    HPO_TERM       0.62      0.67      0.64       392\n","     PATIENT       0.76      0.72      0.74        39\n","\n","   micro avg       0.65      0.69      0.67       574\n","   macro avg       0.55      0.56      0.55       574\n","weighted avg       0.67      0.69      0.68       574\n","\n"]}],"source":["# Generate classification report\n","from seqeval.metrics import classification_report as seqeval_classification_report\n","report = seqeval_classification_report(true_labels, pred_labels, output_dict=True)\n","\n","from sklearn.metrics import accuracy_score\n","from itertools import chain\n","\n","flat_true = list(chain.from_iterable(true_labels))\n","flat_pred = list(chain.from_iterable(pred_labels))\n","\n","accuracy = accuracy_score(flat_true, flat_pred)\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","print(f\"Precision: {report['weighted avg']['precision']:.4f}\")\n","print(f\"Recall: {report['weighted avg']['recall']:.4f}\")\n","print(f\"F1-Score: {report['weighted avg']['f1-score']:.4f}\")\n","\n","print(seqeval_classification_report(true_labels, pred_labels))"]},{"cell_type":"code","execution_count":49,"id":"c71323f4-8bb2-4529-98fe-8a1743581e2c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":291,"status":"ok","timestamp":1756251838535,"user":{"displayName":"宋若冰","userId":"16843204755956256636"},"user_tz":-480},"id":"c71323f4-8bb2-4529-98fe-8a1743581e2c","outputId":"ad89e242-0e35-45c7-c218-61b1c427e734"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9409\n","Precision: 0.7849\n","Recall: 0.7631\n","F1-Score: 0.7716\n","              precision    recall  f1-score   support\n","\n","   AGE_DEATH       0.67      0.44      0.53         9\n","AGE_FOLLOWUP       0.56      0.18      0.27        28\n","   AGE_ONSET       0.27      0.35      0.30        23\n","        GENE       0.89      0.85      0.87        40\n","GENE_VARIANT       0.94      0.85      0.89       180\n","    HPO_TERM       0.77      0.78      0.77      1161\n","     PATIENT       0.75      0.67      0.71        49\n","\n","   micro avg       0.78      0.76      0.77      1490\n","   macro avg       0.69      0.59      0.62      1490\n","weighted avg       0.78      0.76      0.77      1490\n","\n"]}],"source":["from sklearn.metrics import classification_report as sk_classification_report\n","from itertools import chain\n","\n","# Loose matching\n","def is_loose_match(true_tag, pred_tag):\n","    if true_tag != \"O\" and pred_tag != \"O\":\n","        true_entity = true_tag.split(\"-\")[-1]\n","        pred_entity = pred_tag.split(\"-\")[-1]\n","        return true_entity == pred_entity\n","    return False\n","\n","def strip_prefix(tag):\n","    return tag.split(\"-\")[-1] if tag != \"O\" else \"O\"\n","\n","flat_true = list(chain.from_iterable(true_labels))\n","flat_pred = list(chain.from_iterable(pred_labels))\n","\n","adjusted_pred = []\n","for t, p in zip(flat_true, flat_pred):\n","    if is_loose_match(t, p):\n","        adjusted_pred.append(t)\n","    else:\n","        adjusted_pred.append(p)\n","\n","flat_true_no_prefix = [strip_prefix(t) for t in flat_true]\n","adjusted_pred_no_prefix = [strip_prefix(p) for p in adjusted_pred]\n","\n","labels_without_O = sorted((set(flat_true_no_prefix) | set(adjusted_pred_no_prefix)) - {\"O\"})\n","\n","accuracy = accuracy_score(flat_true_no_prefix, adjusted_pred_no_prefix)\n","print(f\"Accuracy: {accuracy:.4f}\")\n","\n","report = sk_classification_report(\n","    flat_true_no_prefix,\n","    adjusted_pred_no_prefix,\n","    labels=labels_without_O,\n","    output_dict=True,\n","    zero_division=0\n",")\n","\n","print(f\"Precision: {report['weighted avg']['precision']:.4f}\")\n","print(f\"Recall: {report['weighted avg']['recall']:.4f}\")\n","print(f\"F1-Score: {report['weighted avg']['f1-score']:.4f}\")\n","\n","print(sk_classification_report(\n","    flat_true_no_prefix,\n","    adjusted_pred_no_prefix,\n","    labels=labels_without_O,\n","    zero_division=0\n","))\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python [conda env:nlp_env]","language":"python","name":"conda-env-nlp_env-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.23"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}